{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Malekkamoua/PFE/blob/main/5_Forecasting%20%7C%20Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFp9nEAHdxX0",
        "outputId": "53cb653c-bf25-4155-8b3a-50cee4d2d48c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_-iNTfdu4g1L"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/gdrive/MyDrive/Datascience/Datasets/final_dataset_fs_db.csv', parse_dates=['dates'],  index_col='dates',infer_datetime_format=True)\n",
        "df.drop(['Unnamed: 0', 'Purity'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pXYnPdWO4iky"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Normalization\n",
        "values = df[['% Silica Concentrate']].values\n",
        "\n",
        "# Normalization\n",
        "scaler = MinMaxScaler()\n",
        "scaled_data = scaler.fit_transform(values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "29bThdEd4lwj"
      },
      "outputs": [],
      "source": [
        "def create_data(series, prev_instances = 4):\n",
        " \n",
        "    X_train_1 = pd.DataFrame(series).astype('float64')\n",
        "    X_train_temp = X_train_1.shift(1)\n",
        "    y_label = X_train_1.shift(-1)\n",
        "    \n",
        "    data = pd.concat([X_train_temp, X_train_1, y_label], axis=1)\n",
        "    \n",
        "    for r in range(prev_instances-2):\n",
        "      X_train_temp = X_train_temp.shift(1)\n",
        "      data = pd.concat([X_train_temp, data], axis=1)\n",
        "    data.dropna(inplace = True)\n",
        "    data.reset_index(drop = True, inplace = True)\n",
        "    # print(data.head(10))\n",
        "    X = data.iloc[:, 0:-1].values \n",
        "    y = data.iloc[:,-1].values \n",
        "    \n",
        "    print('This series takes {} previous instances'.format(prev_instances))\n",
        "    \n",
        "    data.columns = [*data.columns[:-1], 'y']\n",
        "    \n",
        "    return data, X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYkEG3_o43aE",
        "outputId": "7db72689-f00d-4195-bca8-25b70647c58f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This series takes 5 previous instances\n"
          ]
        }
      ],
      "source": [
        "WINDOW_SIZE = 5\n",
        "\n",
        "time_series = scaled_data;\n",
        "data, X, y = create_data(time_series, prev_instances = WINDOW_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ra_glUAK4o3Y",
        "outputId": "2bc0280d-f776-49ef-ed06-8500736a77ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3935, 5), (3935,), (840, 5), (840,), (841, 5), (841,))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# 70% 15% 15%\n",
        "\n",
        "X_train, y_train = X[:3935], y[:3935]\n",
        "X_test, y_test = X[3935:4775], y[3935:4775]\n",
        "X_val, y_val = X[4775:], y[4775:]\n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape, X_val.shape, y_val.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7W19v5fS6OKt",
        "outputId": "6a231821-2f3d-4632-c1a3-0529dd1aa5ce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3935, 5, 1), (3935,), (840, 5, 1), (840,), (841, 5, 1), (841,))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# reshape input to be 3D [samples, timesteps, features]\n",
        "X_train = X_train.reshape((X_train.shape[0], WINDOW_SIZE,1))\n",
        "X_test = X_test.reshape((X_test.shape[0], WINDOW_SIZE, 1))\n",
        "X_val = X_val.reshape((X_val.shape[0], WINDOW_SIZE, 1))\n",
        "\n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape, X_val.shape, y_val.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnSny3oO6TkE"
      },
      "outputs": [],
      "source": [
        "from statsmodels.tsa.stattools import acf\n",
        "\n",
        "def forecast_accuracy(forecast, actual):\n",
        "    mape = np.mean(np.abs(forecast - actual)/np.abs(actual))  \n",
        "    mae = np.mean(np.abs(forecast - actual))    \n",
        "    rmse = np.mean((forecast - actual)**2)**.5  \n",
        "\n",
        "    return mape, mae, rmse"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb -qqq\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "id": "JX35wYP4HKx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_transformer_config = {\n",
        "    \"method\": \"random\", \n",
        "    \"metric\": {\n",
        "      \"name\": \"MAPE\",\n",
        "      \"goal\": \"minimize\"   \n",
        "    },\n",
        "    \"parameters\": {\n",
        "        \n",
        "        \"learning_rate\": {\n",
        "            \"values\": [0.0001, 0.001, 0.005, 0.01]\n",
        "        },\n",
        "        \"epochs\": {\n",
        "            \"values\": [100, 150, 200, 300]\n",
        "        },\n",
        "        \"batch_size\": {\n",
        "            \"values\": [64, 128]\n",
        "        },\n",
        "        \"head_size\": {\n",
        "            \"values\": [128, 256]\n",
        "        },\n",
        "        \"num_heads\": {\n",
        "            \"values\": [4, 8, 16]\n",
        "        },\n",
        "        \"num_transformer_blocks\": {\n",
        "            \"values\": [4, 8]\n",
        "        },\n",
        "        \"mlp_units\": {\n",
        "            \"values\":[64, 128, 256]\n",
        "        },\n",
        "        \"mlp_dropout\": {\n",
        "            \"values\": [0.2, 0.25, 0.3]\n",
        "        },\n",
        "        \"dropout\": {\n",
        "            \"values\": [0.2, 0.25, 0.3]\n",
        "        },\n",
        "        \"hidden_dim\": {\n",
        "            \"values\":[100, 150, 200]\n",
        "        },\n",
        "        \"positional_ff_dim\": {\n",
        "            \"values\":[64, 128, 256]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_transformer_config, project=\"Transformer_shot_7\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjdJaGlhHi3P",
        "outputId": "2babf2f6-cbfa-4f94-ae78-c988a0b2b537"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: fgzo152j\n",
            "Sweep URL: https://wandb.ai/malekkamoua/Transformer_shot_7/sweeps/fgzo152j\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, InputLayer\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.losses import MeanSquaredError, MeanAbsolutePercentageError\n",
        "from keras.metrics import RootMeanSquaredError\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Define early_stopping_monitor\n",
        "from keras.callbacks import EarlyStopping\n",
        "early_stopping_monitor = EarlyStopping(patience=25)\n",
        "\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "def train():\n",
        "  config_defaults = {\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"epochs\": 100,\n",
        "    \"batch_size\": 128,\n",
        "    \"head_size\": 256,\n",
        "    \"num_heads\": 4,\n",
        "    \"num_transformer_blocks\": 4,\n",
        "    \"mlp_units\": 128,\n",
        "    \"mlp_dropout\": 0.2,\n",
        "    \"dropout\": 0.25,\n",
        "    \"hidden_dim\": 100,\n",
        "    \"positional_ff_dim\": 128\n",
        "  }\n",
        "\n",
        "\n",
        "  wandb.init(config=config_defaults)  # defaults are over-ridden during the sweep\n",
        "  config = wandb.config\n",
        "\n",
        "  look_back = 5\n",
        "  n_features = 1\n",
        "  horizon = 1\n",
        "\n",
        "  checkpoint_dir = \"checkpoint\"\n",
        "\n",
        "  head_size = wandb.config['head_size']\n",
        "  num_heads = wandb.config['num_heads']\n",
        "  num_transformer_blocks = wandb.config['num_transformer_blocks']\n",
        "  mlp_units = [wandb.config['mlp_units']] \n",
        "  mlp_dropout = wandb.config['mlp_dropout']\n",
        "  dropout = wandb.config['dropout']\n",
        "  hidden_dim =  wandb.config['hidden_dim']  # Number of neurons in each recurrent unit \n",
        "  positional_ff_dim =  wandb.config['positional_ff_dim']\n",
        "\n",
        "  cp = ModelCheckpoint('model/', save_best_only=True)\n",
        "\n",
        "  inputs = keras.Input(shape=(look_back, n_features))\n",
        "  x = inputs\n",
        "\n",
        "  for _ in range(num_transformer_blocks):\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
        "    x = layers.MultiHeadAttention(\n",
        "    key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "\n",
        "    res = x + inputs\n",
        "\n",
        "    # Feed Forward Part\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
        "    x = layers.Conv1D(filters=positional_ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
        "    x = x + res\n",
        "\n",
        "  x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
        "  for dim in mlp_units:\n",
        "    x = layers.Dense(dim, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(mlp_dropout)(x)\n",
        "  \n",
        "  outputs = layers.Dense(horizon)(x)\n",
        "  model = keras.Model(inputs, outputs)\n",
        "\n",
        "  model.compile( loss = MeanSquaredError(), \n",
        "                    optimizer = Adam(learning_rate= wandb.config['learning_rate']), \n",
        "                    metrics=['mae',\n",
        "                          MeanSquaredError(),\n",
        "                          RootMeanSquaredError(),\n",
        "                          MeanAbsolutePercentageError()])\n",
        "\n",
        "  history = model.fit(X_train, y_train, \n",
        "                      epochs = wandb.config['epochs'] , \n",
        "                      batch_size = wandb.config['batch_size'],\n",
        "                      validation_data=(X_test, y_test),\n",
        "                      callbacks= [early_stopping_monitor, \n",
        "                                  WandbCallback()])  \n",
        "  \n",
        "  \n",
        "  y_pred_val = model.predict(np.asarray(X_val).astype('float32'))\n",
        "  Inverse_y_val = y_val.reshape(-1,1)\n",
        "  Inverse_y_val = scaler.inverse_transform(Inverse_y_val)\n",
        "  Inverse_y_pred_val = scaler.inverse_transform(y_pred_val)\n",
        "\n",
        "  mape, mae, rmse = forecast_accuracy(Inverse_y_pred_val, Inverse_y_val)\n",
        "\n",
        "  wandb.log({\"MAPE\": mape, \"MAE\": mae, \"RMSE\": rmse})\n",
        "\n",
        "  wandb.finish()"
      ],
      "metadata": {
        "id": "I-2U8fvuIwJl"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.agent(sweep_id, train, count=200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 984
        },
        "id": "KjZikD_uKM2a",
        "outputId": "88515225-7ab8-4ca2-c0f5-0cb7bfe7d42f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: l9vh7psr with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 300\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thead_size: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 200\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmlp_dropout: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmlp_units: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_heads: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_transformer_blocks: 8\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tpositional_ff_dim: 128\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220519_120935-l9vh7psr</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/malekkamoua/Transformer_shot_7/runs/l9vh7psr\" target=\"_blank\">different-sweep-1</a></strong> to <a href=\"https://wandb.ai/malekkamoua/Transformer_shot_7\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/malekkamoua/Transformer_shot_7/sweeps/fgzo152j\" target=\"_blank\">https://wandb.ai/malekkamoua/Transformer_shot_7/sweeps/fgzo152j</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "62/62 [==============================] - 7s 84ms/step - loss: 0.1109 - mae: 0.2552 - mean_squared_error: 0.1106 - root_mean_squared_error: 0.3329 - mean_absolute_percentage_error: 85.3043 - val_loss: 0.0317 - val_mae: 0.1528 - val_mean_squared_error: 0.0331 - val_root_mean_squared_error: 0.1779 - val_mean_absolute_percentage_error: 71.7296 - _timestamp: 1652962187.0000 - _runtime: 12.0000\n",
            "Epoch 2/300\n",
            "62/62 [==============================] - 5s 82ms/step - loss: 0.0351 - mae: 0.1450 - mean_squared_error: 0.0352 - root_mean_squared_error: 0.1875 - mean_absolute_percentage_error: 49.9656 - val_loss: 0.0192 - val_mae: 0.0973 - val_mean_squared_error: 0.0191 - val_root_mean_squared_error: 0.1385 - val_mean_absolute_percentage_error: 33.3010 - _timestamp: 1652962192.0000 - _runtime: 17.0000\n",
            "Epoch 3/300\n",
            "62/62 [==============================] - 5s 79ms/step - loss: 0.0245 - mae: 0.1137 - mean_squared_error: 0.0246 - root_mean_squared_error: 0.1564 - mean_absolute_percentage_error: 37.2266 - val_loss: 0.0173 - val_mae: 0.0887 - val_mean_squared_error: 0.0168 - val_root_mean_squared_error: 0.1315 - val_mean_absolute_percentage_error: 30.3358 - _timestamp: 1652962197.0000 - _runtime: 22.0000\n",
            "Epoch 4/300\n",
            "62/62 [==============================] - 5s 79ms/step - loss: 0.0202 - mae: 0.0981 - mean_squared_error: 0.0201 - root_mean_squared_error: 0.1422 - mean_absolute_percentage_error: 32.2183 - val_loss: 0.0168 - val_mae: 0.0912 - val_mean_squared_error: 0.0169 - val_root_mean_squared_error: 0.1295 - val_mean_absolute_percentage_error: 40.7990 - _timestamp: 1652962202.0000 - _runtime: 27.0000\n",
            "Epoch 5/300\n",
            "62/62 [==============================] - 5s 82ms/step - loss: 0.0186 - mae: 0.0891 - mean_squared_error: 0.0190 - root_mean_squared_error: 0.1365 - mean_absolute_percentage_error: 29.5810 - val_loss: 0.0156 - val_mae: 0.0789 - val_mean_squared_error: 0.0156 - val_root_mean_squared_error: 0.1248 - val_mean_absolute_percentage_error: 31.7548 - _timestamp: 1652962207.0000 - _runtime: 32.0000\n",
            "Epoch 6/300\n",
            "62/62 [==============================] - 5s 83ms/step - loss: 0.0188 - mae: 0.0912 - mean_squared_error: 0.0189 - root_mean_squared_error: 0.1373 - mean_absolute_percentage_error: 30.0541 - val_loss: 0.0173 - val_mae: 0.0908 - val_mean_squared_error: 0.0178 - val_root_mean_squared_error: 0.1315 - val_mean_absolute_percentage_error: 40.9356 - _timestamp: 1652962212.0000 - _runtime: 37.0000\n",
            "Epoch 7/300\n",
            "62/62 [==============================] - 5s 79ms/step - loss: 0.0183 - mae: 0.0879 - mean_squared_error: 0.0183 - root_mean_squared_error: 0.1354 - mean_absolute_percentage_error: 28.9447 - val_loss: 0.0157 - val_mae: 0.0807 - val_mean_squared_error: 0.0156 - val_root_mean_squared_error: 0.1252 - val_mean_absolute_percentage_error: 31.1456 - _timestamp: 1652962217.0000 - _runtime: 42.0000\n",
            "Epoch 8/300\n",
            "62/62 [==============================] - 5s 80ms/step - loss: 0.0181 - mae: 0.0866 - mean_squared_error: 0.0180 - root_mean_squared_error: 0.1345 - mean_absolute_percentage_error: 28.6765 - val_loss: 0.0168 - val_mae: 0.0864 - val_mean_squared_error: 0.0173 - val_root_mean_squared_error: 0.1297 - val_mean_absolute_percentage_error: 38.0738 - _timestamp: 1652962222.0000 - _runtime: 47.0000\n",
            "Epoch 9/300\n",
            "62/62 [==============================] - 5s 81ms/step - loss: 0.0179 - mae: 0.0844 - mean_squared_error: 0.0180 - root_mean_squared_error: 0.1340 - mean_absolute_percentage_error: 27.7371 - val_loss: 0.0155 - val_mae: 0.0771 - val_mean_squared_error: 0.0155 - val_root_mean_squared_error: 0.1245 - val_mean_absolute_percentage_error: 30.1845 - _timestamp: 1652962227.0000 - _runtime: 52.0000\n",
            "Epoch 10/300\n",
            "62/62 [==============================] - 5s 79ms/step - loss: 0.0180 - mae: 0.0864 - mean_squared_error: 0.0180 - root_mean_squared_error: 0.1342 - mean_absolute_percentage_error: 28.5319 - val_loss: 0.0158 - val_mae: 0.0705 - val_mean_squared_error: 0.0155 - val_root_mean_squared_error: 0.1256 - val_mean_absolute_percentage_error: 25.2389 - _timestamp: 1652962232.0000 - _runtime: 57.0000\n",
            "Epoch 11/300\n",
            "62/62 [==============================] - 5s 78ms/step - loss: 0.0179 - mae: 0.0849 - mean_squared_error: 0.0179 - root_mean_squared_error: 0.1336 - mean_absolute_percentage_error: 28.2566 - val_loss: 0.0156 - val_mae: 0.0796 - val_mean_squared_error: 0.0156 - val_root_mean_squared_error: 0.1249 - val_mean_absolute_percentage_error: 33.1029 - _timestamp: 1652962237.0000 - _runtime: 62.0000\n",
            "Epoch 12/300\n",
            "62/62 [==============================] - 5s 77ms/step - loss: 0.0179 - mae: 0.0853 - mean_squared_error: 0.0178 - root_mean_squared_error: 0.1337 - mean_absolute_percentage_error: 28.5468 - val_loss: 0.0155 - val_mae: 0.0758 - val_mean_squared_error: 0.0153 - val_root_mean_squared_error: 0.1247 - val_mean_absolute_percentage_error: 28.1560 - _timestamp: 1652962242.0000 - _runtime: 67.0000\n",
            "Epoch 13/300\n",
            "62/62 [==============================] - 5s 76ms/step - loss: 0.0187 - mae: 0.0880 - mean_squared_error: 0.0189 - root_mean_squared_error: 0.1368 - mean_absolute_percentage_error: 28.9208 - val_loss: 0.0163 - val_mae: 0.0826 - val_mean_squared_error: 0.0160 - val_root_mean_squared_error: 0.1278 - val_mean_absolute_percentage_error: 28.3823 - _timestamp: 1652962246.0000 - _runtime: 71.0000\n",
            "Epoch 14/300\n",
            "62/62 [==============================] - 5s 76ms/step - loss: 0.0192 - mae: 0.0921 - mean_squared_error: 0.0191 - root_mean_squared_error: 0.1386 - mean_absolute_percentage_error: 30.5941 - val_loss: 0.0157 - val_mae: 0.0805 - val_mean_squared_error: 0.0157 - val_root_mean_squared_error: 0.1253 - val_mean_absolute_percentage_error: 34.1894 - _timestamp: 1652962251.0000 - _runtime: 76.0000\n",
            "Epoch 15/300\n",
            "62/62 [==============================] - 5s 88ms/step - loss: 0.0174 - mae: 0.0827 - mean_squared_error: 0.0174 - root_mean_squared_error: 0.1320 - mean_absolute_percentage_error: 27.5558 - val_loss: 0.0167 - val_mae: 0.0845 - val_mean_squared_error: 0.0170 - val_root_mean_squared_error: 0.1294 - val_mean_absolute_percentage_error: 36.7608 - _timestamp: 1652962257.0000 - _runtime: 82.0000\n",
            "Epoch 16/300\n",
            "62/62 [==============================] - 5s 78ms/step - loss: 0.0173 - mae: 0.0839 - mean_squared_error: 0.0173 - root_mean_squared_error: 0.1316 - mean_absolute_percentage_error: 27.8678 - val_loss: 0.0156 - val_mae: 0.0753 - val_mean_squared_error: 0.0154 - val_root_mean_squared_error: 0.1250 - val_mean_absolute_percentage_error: 27.1827 - _timestamp: 1652962261.0000 - _runtime: 86.0000\n",
            "Epoch 17/300\n",
            "62/62 [==============================] - 5s 79ms/step - loss: 0.0181 - mae: 0.0856 - mean_squared_error: 0.0181 - root_mean_squared_error: 0.1344 - mean_absolute_percentage_error: 28.3544 - val_loss: 0.0156 - val_mae: 0.0788 - val_mean_squared_error: 0.0155 - val_root_mean_squared_error: 0.1250 - val_mean_absolute_percentage_error: 30.4909 - _timestamp: 1652962266.0000 - _runtime: 91.0000\n",
            "Epoch 18/300\n",
            " 5/62 [=>............................] - ETA: 3s - loss: 0.0177 - mae: 0.0860 - mean_squared_error: 0.0177 - root_mean_squared_error: 0.1331 - mean_absolute_percentage_error: 27.9139"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of 5_Forecasting | Transformer.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMSV66i1ThZhI4qxLxxVI5h",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}