{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Malekkamoua/PFE/blob/main/.addixo/5_Forecasting_%7C_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlkW9AaUSxoP",
        "outputId": "c03ca742-2fb8-4064-8e14-caa78a282e41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJpRxlZQjkLQ"
      },
      "outputs": [],
      "source": [
        "!pip install wandb -qqq\n",
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "laR52G-wUG1g"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/gdrive/MyDrive/Datascience/PFE/datasets/addixo_final_dataset_fs_db.csv', parse_dates=['dates'],  index_col='dates',infer_datetime_format=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0l6A0dfSUUxg"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from matplotlib.pyplot import figure\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from keras.models import load_model\n",
        "from keras.layers import LSTM\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PKFTtIioUrmg"
      },
      "outputs": [],
      "source": [
        "# Normalization\n",
        "values = df[['duration']].values\n",
        "\n",
        "# Normalization\n",
        "scaler = MinMaxScaler()\n",
        "scaled_data = scaler.fit_transform(values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hhf5cP92UebK"
      },
      "outputs": [],
      "source": [
        "def create_data(series, prev_instances = 4):\n",
        " \n",
        "    X_train_1 = pd.DataFrame(series).astype('float64')\n",
        "    X_train_temp = X_train_1.shift(1)\n",
        "    y_label = X_train_1.shift(-1)\n",
        "    \n",
        "    data = pd.concat([X_train_temp, X_train_1, y_label], axis=1)\n",
        "    \n",
        "    for r in range(prev_instances-2):\n",
        "      X_train_temp = X_train_temp.shift(1)\n",
        "      data = pd.concat([X_train_temp, data], axis=1)\n",
        "    data.dropna(inplace = True)\n",
        "    data.reset_index(drop = True, inplace = True)\n",
        "    # print(data.head(10))\n",
        "    X = data.iloc[:, 0:-1].values \n",
        "    y = data.iloc[:,-1].values \n",
        "    \n",
        "    print('This series takes {} previous instances'.format(prev_instances))\n",
        "    \n",
        "    data.columns = [*data.columns[:-1], 'y']\n",
        "    \n",
        "    return data, X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsRht3qUYQRv",
        "outputId": "153fdbcf-c090-4ef7-f918-9920dedd37df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This series takes 5 previous instances\n"
          ]
        }
      ],
      "source": [
        "WINDOW_SIZE = 5\n",
        "\n",
        "time_series = scaled_data;\n",
        "data, X, y = create_data(time_series, prev_instances = WINDOW_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQeEwicqWPI4",
        "outputId": "d41a4f5b-78dc-4c97-80b6-9098b287edce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((57153, 5), (57153,), (12247, 5), (12247,), (12242, 5), (12242,))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# 70% 15% 15%\n",
        "\n",
        "X_train, y_train = X[:57153], y[:57153]\n",
        "X_test, y_test = X[57153:69400], y[57153:69400]\n",
        "X_val, y_val = X[69400:], y[69400:]\n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape, X_val.shape, y_val.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y04LFqF4e316"
      },
      "source": [
        "You always have to give a three-dimensional array as an input to your LSTM network. Where the first dimension represents the batch size, the second dimension represents the number of time-steps you are feeding a sequence. And the third dimension represents the number of units in one input sequence. For example, input shape looks like (batch_size, time_steps, seq_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YGX7cIJY5Fv",
        "outputId": "6af2e42c-addd-4617-962b-f4dd254260dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((57153, 5, 1), (57153,), (12247, 5, 1), (12247,), (12242, 5, 1), (12242,))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# reshape input to be 3D [samples, timesteps, features]\n",
        "X_train = X_train.reshape((X_train.shape[0], WINDOW_SIZE,1))\n",
        "X_test = X_test.reshape((X_test.shape[0], WINDOW_SIZE, 1))\n",
        "X_val = X_val.reshape((X_val.shape[0], WINDOW_SIZE, 1))\n",
        "    \n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape, X_val.shape, y_val.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhqVUNbof-5o"
      },
      "outputs": [],
      "source": [
        "from statsmodels.tsa.stattools import acf\n",
        "\n",
        "def forecast_accuracy(forecast, actual):\n",
        "    mape = np.mean(np.abs(forecast - actual)/np.abs(actual))  \n",
        "    mae = np.mean(np.abs(forecast - actual))    \n",
        "    rmse = np.mean((forecast - actual)**2)**.5  \n",
        "\n",
        "    return mape, mae, rmse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_C4HkbIlbxy",
        "outputId": "08c2aa57-d38c-4d15-cf97-23dda176d0b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Create sweep with ID: yhjuxdf0\n",
            "Sweep URL: https://wandb.ai/malekkamoua/Stacked_lstm_shot_2/sweeps/yhjuxdf0\n"
          ]
        }
      ],
      "source": [
        "sweep_lstm_config = {\n",
        "    \"method\": \"random\", # try grid or random\n",
        "    \"metric\": {\n",
        "      \"name\": \"MAPE\",\n",
        "      \"goal\": \"minimize\"   \n",
        "    },\n",
        "    \"parameters\": {\n",
        "          \"learning_rate\": {\n",
        "            \"values\": [0.001, 0.025, 0.01]\n",
        "        },\n",
        "        \"epochs\": {\n",
        "            \"values\": [100, 200, 300]\n",
        "        },\n",
        "        \n",
        "        \"batch_size\": {\n",
        "            \"values\": [32, 64, 128]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_lstm_config, project=\"Stacked_lstm_shot_2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8jtvNcvHlhMg"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, InputLayer\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.losses import MeanSquaredError, MeanAbsolutePercentageError\n",
        "from keras.metrics import RootMeanSquaredError\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Define early_stopping_monitor\n",
        "from keras.callbacks import EarlyStopping\n",
        "early_stopping_monitor = EarlyStopping(patience=2)\n",
        "\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "def train():\n",
        "  config_defaults = {\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"epochs\": 100,\n",
        "    \"batch_size\": 32,\n",
        "    'shuffle': False\n",
        "  }\n",
        "\n",
        "  wandb.init(config=config_defaults)  # defaults are over-ridden during the sweep\n",
        "  config = wandb.config\n",
        "\n",
        "  cp = ModelCheckpoint('model/', save_best_only=True)\n",
        "\n",
        "  #define the model\n",
        "  model=Sequential()\n",
        "  model.add(LSTM(100,return_sequences=True,input_shape=(X_train.shape[1],1)))\n",
        "  model.add(LSTM(100,return_sequences=True))\n",
        "  model.add(LSTM(100,return_sequences=True))\n",
        "  model.add(Dense(50, activation='relu'))\n",
        "  model.add(LSTM(50,return_sequences=True))\n",
        "  model.add(LSTM(50))\n",
        "  model.add(Dense(1))\n",
        "  \n",
        "  model.compile( loss = MeanSquaredError(), \n",
        "                    optimizer = Adam(learning_rate= wandb.config['learning_rate']), \n",
        "                    metrics=['mae',\n",
        "                          MeanSquaredError(),\n",
        "                          RootMeanSquaredError(),\n",
        "                          MeanAbsolutePercentageError()])\n",
        "\n",
        "  history = model.fit(X_train, y_train, \n",
        "                      epochs = wandb.config['epochs'] , \n",
        "                      batch_size = wandb.config['batch_size'],\n",
        "                      shuffle = wandb.config['shuffle'],\n",
        "                      validation_data=(X_test, y_test),\n",
        "                      callbacks= [early_stopping_monitor, \n",
        "                                  WandbCallback()])  \n",
        "  \n",
        "  y_pred_test_LSTM = model.predict(np.asarray(X_test).astype('float32'))\n",
        "  Inverse_y_test = y_test.reshape(-1,1)\n",
        "  Inverse_y_test = scaler.inverse_transform(Inverse_y_test)\n",
        "  Inverse_y_pred_test_LSTM = y_pred_test_LSTM.reshape(-1,1)\n",
        "  Inverse_y_pred_test_LSTM = scaler.inverse_transform(Inverse_y_pred_test_LSTM)\n",
        "\n",
        "  mape, mae, rmse = forecast_accuracy(Inverse_y_pred_test_LSTM, Inverse_y_test)\n",
        "\n",
        "  wandb.log({\"MAPE\": mape})\n",
        "\n",
        "  wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHqOpH5mmGAf"
      },
      "outputs": [],
      "source": [
        "wandb.agent(sweep_id, train, count=40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-uTqc-u57Zz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7cf3d46-a216-4860-d578-33ad25832eb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1653645715.0028002\n",
            "Epoch 1/3\n",
            "446/447 [============================>.] - ETA: 0s - loss: 0.0054 - mae: 0.0406 - mean_squared_error: 0.0054 - root_mean_squared_error: 0.0738 - mean_absolute_percentage_error: 10995.0547"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: model/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f08ca6d8f90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f08c6924e10> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f08c67b8b90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f08c667fd90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f08c6652f90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r447/447 [==============================] - 62s 116ms/step - loss: 0.0054 - mae: 0.0406 - mean_squared_error: 0.0054 - root_mean_squared_error: 0.0738 - mean_absolute_percentage_error: 10970.4756 - val_loss: 0.0022 - val_mae: 0.0232 - val_mean_squared_error: 0.0022 - val_root_mean_squared_error: 0.0467 - val_mean_absolute_percentage_error: 51.9171\n",
            "Epoch 2/3\n",
            "446/447 [============================>.] - ETA: 0s - loss: 0.0035 - mae: 0.0297 - mean_squared_error: 0.0035 - root_mean_squared_error: 0.0593 - mean_absolute_percentage_error: 10008.6045"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: model/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f08ca6d8f90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f08c6924e10> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f08c67b8b90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f08c667fd90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f08c6652f90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r447/447 [==============================] - 50s 111ms/step - loss: 0.0035 - mae: 0.0297 - mean_squared_error: 0.0035 - root_mean_squared_error: 0.0593 - mean_absolute_percentage_error: 9986.2246 - val_loss: 0.0014 - val_mae: 0.0160 - val_mean_squared_error: 0.0014 - val_root_mean_squared_error: 0.0381 - val_mean_absolute_percentage_error: 41.1376\n",
            "Epoch 3/3\n",
            "446/447 [============================>.] - ETA: 0s - loss: 0.0030 - mae: 0.0254 - mean_squared_error: 0.0030 - root_mean_squared_error: 0.0548 - mean_absolute_percentage_error: 10477.0107"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: model/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f08ca6d8f90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f08c6924e10> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f08c67b8b90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f08c667fd90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f08c6652f90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r447/447 [==============================] - 51s 114ms/step - loss: 0.0030 - mae: 0.0253 - mean_squared_error: 0.0030 - root_mean_squared_error: 0.0548 - mean_absolute_percentage_error: 10453.5723 - val_loss: 0.0012 - val_mae: 0.0136 - val_mean_squared_error: 0.0012 - val_root_mean_squared_error: 0.0346 - val_mean_absolute_percentage_error: 34.2800\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, InputLayer\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.losses import MeanSquaredError, MeanAbsolutePercentageError\n",
        "from keras.metrics import RootMeanSquaredError\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Define early_stopping_monitor\n",
        "from keras.callbacks import EarlyStopping\n",
        "early_stopping_monitor = EarlyStopping(patience=5)\n",
        "\n",
        "cp = ModelCheckpoint('model/', save_best_only=True)\n",
        "\n",
        "#define the model\n",
        "model=Sequential()\n",
        "model.add(LSTM(100,return_sequences=True,input_shape=(X_train.shape[1],1)))\n",
        "model.add(LSTM(100,return_sequences=True))\n",
        "model.add(LSTM(100,return_sequences=True))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(LSTM(50,return_sequences=True))\n",
        "model.add(LSTM(50))\n",
        "model.add(Dense(1))\n",
        "model.compile( loss = MeanSquaredError(), \n",
        "                  optimizer = Adam(learning_rate= 0.001), \n",
        "                  metrics=['mae',\n",
        "                        MeanSquaredError(),\n",
        "                        RootMeanSquaredError(),\n",
        "                        MeanAbsolutePercentageError()])\n",
        "\n",
        "start = time.time()\n",
        "print(start)\n",
        "history_LSTM = model.fit(X_train, y_train, \n",
        "                              epochs = 3 , \n",
        "                              batch_size = 128,\n",
        "                              shuffle =False,\n",
        "                              validation_data=(X_test, y_test),\n",
        "                              callbacks= [cp,\n",
        "                                          early_stopping_monitor])   \n",
        "\n",
        "stop = time.time()\n",
        "print(stop)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Training time: {stop - start}s\")  "
      ],
      "metadata": {
        "id": "FTlonFbJOLt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4ra8hti7It9"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zvI-couEhDwj"
      },
      "outputs": [],
      "source": [
        "y_pred_train_LSTM = model.predict(np.asarray(X_train).astype('float32'))\n",
        "Inverse_y_train = y_train.reshape(-1,1)\n",
        "Inverse_y_train = scaler.inverse_transform(Inverse_y_train)\n",
        "Inverse_y_pred_train_LSTM = y_pred_train_LSTM.reshape(-1,1)\n",
        "Inverse_y_pred_train_LSTM = scaler.inverse_transform(Inverse_y_pred_train_LSTM)\n",
        "\n",
        "y_pred_test_LSTM = model.predict(np.asarray(X_test).astype('float32'))\n",
        "Inverse_y_test = y_test.reshape(-1,1)\n",
        "Inverse_y_test = scaler.inverse_transform(Inverse_y_test)\n",
        "Inverse_y_pred_test_LSTM = y_pred_test_LSTM.reshape(-1,1)\n",
        "Inverse_y_pred_test_LSTM = scaler.inverse_transform(Inverse_y_pred_test_LSTM)\n",
        "\n",
        "y_pred_val_LSTM = model.predict(np.asarray(X_val).astype('float32'))\n",
        "Inverse_y_val = y_val.reshape(-1,1)\n",
        "Inverse_y_val = scaler.inverse_transform(Inverse_y_val)\n",
        "Inverse_y_pred_val_LSTM = y_pred_val_LSTM.reshape(-1,1)\n",
        "Inverse_y_pred_val_LSTM = scaler.inverse_transform(Inverse_y_pred_val_LSTM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p10KMu9WZw24"
      },
      "outputs": [],
      "source": [
        "mape, mae, rmse = forecast_accuracy(Inverse_y_pred_train_LSTM, Inverse_y_train)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(20,5))\n",
        "plt.plot(Inverse_y_train[0:100], color='orange')\n",
        "plt.plot(Inverse_y_pred_train_LSTM[0:100])\n",
        "plt.title(\"Train Predictions with LSTM [RMSE = %.3f, MAPE = %.3f , MAE = %.3f]\" % (rmse, mape, mae) )\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TaWP8mnShpZA"
      },
      "outputs": [],
      "source": [
        "mape, mae, rmse = forecast_accuracy(Inverse_y_pred_test_LSTM, Inverse_y_test)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(20,5))\n",
        "plt.plot(Inverse_y_test[0:100], color='orange')\n",
        "plt.plot(Inverse_y_pred_test_LSTM[0:100])\n",
        "plt.title(\"Test Predictions with LSTM [RMSE = %.3f, MAPE = %.3f , MAE = %.3f]\" % (rmse, mape, mae) )\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SlW5MdxPGOhG"
      },
      "outputs": [],
      "source": [
        "mape, mae, rmse = forecast_accuracy(Inverse_y_pred_val_LSTM, Inverse_y_val)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(20,5))\n",
        "plt.plot(Inverse_y_val[0:100], color='orange')\n",
        "plt.plot(Inverse_y_pred_val_LSTM[0:100])\n",
        "plt.title(\"Validation Predictions with LSTM [RMSE = %.3f, MAPE = %.3f , MAE = %.3f]\" % (rmse, mape, mae) )\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbAbYPeKxxWf"
      },
      "source": [
        "## View report âœ…\n",
        "https://wandb.ai/malekkamoua/Stacked_lstm_shot_2/reports/Untitled-Report--VmlldzoxOTczNDc1?accessToken=ul18m2tv2ozhqo6w8gk93fi4edfepqzua9uld3p6dvd7ost5e4yavjwl0wu95yo3"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "5_Forecasting | LSTM.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNsEhet1Z21Rw8mQMl2LMDK",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}